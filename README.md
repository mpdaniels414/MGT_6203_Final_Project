# Credit Classification Conundrum: Loan Default Prediction

## Overview
This project explores the application of machine learning algorithms to predict loan defaults, aiming to optimize the underwriting process. By automating the classification of "safe" and "at-risk" loans, financial institutions can significantly reduce operational costs while improving accuracy. The study evaluates multiple models, including XGBoost, Random Forest, Logistic Regression, and SVM, to identify the most effective techniques for binary classification problems in loan underwriting.

### Project Structure
- **Code**: Contains all the scripts required to run the models and generate the visualizations, charts, and metrics for the experiments. Follow the detailed instructions in the `readme.txt` file located within the folder.
- **Data**: Includes links to the team's data sources for easy access and reproducibility.

---

## Dataset
The dataset for this project was sourced from Kaggle. It includes:
- **application_train**: Demographic and credit-related details of loan applicants (122 columns).
- **bureau**: Credit bureau-related debts (17 columns).  

These datasets were merged using the `SK_ID_CURR` key, forming a one-to-many relationship.

### Data Preparation Steps:
1. **Consolidation**: Summed `AMT_CREDIT_SUM` and `AMT_CREDIT_SUM_DEBT` fields for simplicity.
2. **Missing Values**: Imputed missing data in key fields using means or defaults.
3. **Outliers**: Managed extreme values for variables like `CNT_CHILDREN` and income.
4. **Dimensionality Reduction**: Reduced dataset to 49 critical features, focusing on predictive power.

Key variables include:
- `AMT_CREDIT_SUM`
- `AMT_CREDIT_SUM_DEBT`
- Features from the `EXT_SOURCE` series.

---

## Instructions for Running R Files
The following R files implement the machine learning models and generate insights:
1. **XGBoost.Rmd**
2. **RF_SH.R**
3. **Logistic_Regression.R**
4. **svm_knn_model_v2.R**

### Steps:
1. **Download the Dataset**:
   - Access the dataset: [Dropbox Link](https://www.dropbox.com/scl/fo/fz2n66us55x0m4rvln9k7/ALZS02yyjGtyDc3BTfPJO0Q?rlkey=y64730ei3t1r7ui8t3mag3hod&dl=0).
   - Download the file `2024-04-10 - pared.csv`.
2. **Open R/Rmd File**:
   - Select and open one of the listed R or Rmd files in RStudio.
3. **Set the File Path**:
   - Replace the file path in the `read.csv()` function with the location of the `2024-04-10 - pared.csv` file on your computer.
4. **Run the R/Rmd File**:
   - Execute the file in RStudio to process the dataset and generate results.

### Outputs:
- **Graphics and Visualizations**: Generated by `XGBoost.Rmd`.
- **Model Results**: Displayed for XGBoost, Random Forest, Logistic Regression, and SVM.

---

## Models Used
1. **XGBoost**:
   - High adaptability and efficiency.
   - Achieved the highest accuracy: **91.83%** (cutoff: 0.7).
   - Handles sparse data and diverse feature types effectively.
2. **Random Forest**:
   - Ensemble method reducing overfitting risks.
   - Suitable for nonlinear data with large feature sets.
3. **Logistic Regression**:
   - Provides interpretable results.
   - Ideal for binary classification.
4. **Support Vector Machine (SVM)**:
   - Constructs hyperplanes for high-dimensional classification.
5. **K-Nearest Neighbors (KNN)**:
   - Proximity-based classifier, optimized using the best `k` value.

---

## Evaluation Metrics
- **Confusion Matrices**: Used to compare models' performance.
- **Threshold Analysis**: Adjusted cutoff points to balance sensitivity (true positive rate) and specificity (true negative rate).
- **Cost-Optimization**:
  - Cost of false positives: $10,000.
  - Cost of false negatives: $50,000.
  - Optimal cutoff threshold: **0.175**, reducing costs by 13.88%.

---

## Key Findings
1. **Best Model**: XGBoost, with high accuracy and cost-efficiency.
2. **Feature Insights**: `AMT_CREDIT_SUM` and `EXT_SOURCE` series significantly influenced predictions.
3. **Optimal Threshold**: Adjusted to minimize costly false negatives, saving $36.8 million compared to the most accurate threshold.

---

## Ethical Considerations
Machine learning models may inadvertently introduce biases due to sensitive variables like gender and location. To mitigate risks:
- **Feature Selection**: Remove sensitive variables.
- **Demographic Testing**: Ensure equitable performance across groups.
- **Continuous Monitoring**: Update the model to address biases and align with emerging legal standards.

---

## Future Directions
1. Incorporate additional datasets for richer insights.
2. Explore advanced modeling techniques, including ensemble methods.
3. Develop tools for real-time predictions.

---

## Conclusion
This project demonstrates the power of machine learning in financial risk assessment. By integrating ethical considerations and cost-optimization strategies, the study highlights how advanced analytics can transform loan underwriting while ensuring fairness and compliance.

For code and further details, visit the [GitHub Repository](https://github.gatech.edu/MGT-6203-Spring-2024-Canvas/Team-4/tree/main/Code).

